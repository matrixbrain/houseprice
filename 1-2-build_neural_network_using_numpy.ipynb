{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2604e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 / iter   0, loss = 1.7083\n",
      "Epoch   0 / iter   1, loss = 0.9106\n",
      "Epoch   0 / iter   2, loss = 0.3617\n",
      "Epoch   0 / iter   3, loss = 0.2644\n",
      "Epoch   0 / iter   4, loss = 0.1828\n",
      "Epoch   1 / iter   0, loss = 0.2243\n",
      "Epoch   1 / iter   1, loss = 0.1619\n",
      "Epoch   1 / iter   2, loss = 0.1134\n",
      "Epoch   1 / iter   3, loss = 0.1812\n",
      "Epoch   1 / iter   4, loss = 0.1741\n",
      "Epoch   2 / iter   0, loss = 0.1762\n",
      "Epoch   2 / iter   1, loss = 0.1234\n",
      "Epoch   2 / iter   2, loss = 0.1217\n",
      "Epoch   2 / iter   3, loss = 0.1396\n",
      "Epoch   2 / iter   4, loss = 0.0783\n",
      "Epoch   3 / iter   0, loss = 0.1509\n",
      "Epoch   3 / iter   1, loss = 0.1291\n",
      "Epoch   3 / iter   2, loss = 0.1250\n",
      "Epoch   3 / iter   3, loss = 0.1201\n",
      "Epoch   3 / iter   4, loss = 0.2345\n",
      "Epoch   4 / iter   0, loss = 0.1392\n",
      "Epoch   4 / iter   1, loss = 0.1254\n",
      "Epoch   4 / iter   2, loss = 0.0953\n",
      "Epoch   4 / iter   3, loss = 0.1571\n",
      "Epoch   4 / iter   4, loss = 0.1610\n",
      "Epoch   5 / iter   0, loss = 0.1081\n",
      "Epoch   5 / iter   1, loss = 0.1352\n",
      "Epoch   5 / iter   2, loss = 0.1130\n",
      "Epoch   5 / iter   3, loss = 0.1278\n",
      "Epoch   5 / iter   4, loss = 0.1536\n",
      "Epoch   6 / iter   0, loss = 0.1230\n",
      "Epoch   6 / iter   1, loss = 0.1161\n",
      "Epoch   6 / iter   2, loss = 0.1309\n",
      "Epoch   6 / iter   3, loss = 0.1179\n",
      "Epoch   6 / iter   4, loss = 0.0950\n",
      "Epoch   7 / iter   0, loss = 0.1116\n",
      "Epoch   7 / iter   1, loss = 0.1111\n",
      "Epoch   7 / iter   2, loss = 0.1157\n",
      "Epoch   7 / iter   3, loss = 0.1111\n",
      "Epoch   7 / iter   4, loss = 0.0956\n",
      "Epoch   8 / iter   0, loss = 0.0990\n",
      "Epoch   8 / iter   1, loss = 0.0983\n",
      "Epoch   8 / iter   2, loss = 0.1359\n",
      "Epoch   8 / iter   3, loss = 0.1052\n",
      "Epoch   8 / iter   4, loss = 0.0342\n",
      "Epoch   9 / iter   0, loss = 0.1099\n",
      "Epoch   9 / iter   1, loss = 0.1036\n",
      "Epoch   9 / iter   2, loss = 0.1002\n",
      "Epoch   9 / iter   3, loss = 0.1098\n",
      "Epoch   9 / iter   4, loss = 0.1494\n",
      "Epoch  10 / iter   0, loss = 0.0887\n",
      "Epoch  10 / iter   1, loss = 0.1203\n",
      "Epoch  10 / iter   2, loss = 0.1125\n",
      "Epoch  10 / iter   3, loss = 0.0948\n",
      "Epoch  10 / iter   4, loss = 0.1545\n",
      "Epoch  11 / iter   0, loss = 0.0932\n",
      "Epoch  11 / iter   1, loss = 0.1133\n",
      "Epoch  11 / iter   2, loss = 0.1008\n",
      "Epoch  11 / iter   3, loss = 0.0907\n",
      "Epoch  11 / iter   4, loss = 0.0675\n",
      "Epoch  12 / iter   0, loss = 0.1183\n",
      "Epoch  12 / iter   1, loss = 0.0924\n",
      "Epoch  12 / iter   2, loss = 0.0992\n",
      "Epoch  12 / iter   3, loss = 0.0754\n",
      "Epoch  12 / iter   4, loss = 0.0920\n",
      "Epoch  13 / iter   0, loss = 0.0950\n",
      "Epoch  13 / iter   1, loss = 0.0962\n",
      "Epoch  13 / iter   2, loss = 0.0808\n",
      "Epoch  13 / iter   3, loss = 0.1060\n",
      "Epoch  13 / iter   4, loss = 0.1064\n",
      "Epoch  14 / iter   0, loss = 0.0887\n",
      "Epoch  14 / iter   1, loss = 0.1037\n",
      "Epoch  14 / iter   2, loss = 0.0905\n",
      "Epoch  14 / iter   3, loss = 0.0907\n",
      "Epoch  14 / iter   4, loss = 0.0490\n",
      "Epoch  15 / iter   0, loss = 0.0846\n",
      "Epoch  15 / iter   1, loss = 0.0898\n",
      "Epoch  15 / iter   2, loss = 0.0925\n",
      "Epoch  15 / iter   3, loss = 0.0871\n",
      "Epoch  15 / iter   4, loss = 0.1291\n",
      "Epoch  16 / iter   0, loss = 0.1080\n",
      "Epoch  16 / iter   1, loss = 0.0902\n",
      "Epoch  16 / iter   2, loss = 0.0827\n",
      "Epoch  16 / iter   3, loss = 0.0855\n",
      "Epoch  16 / iter   4, loss = 0.0565\n",
      "Epoch  17 / iter   0, loss = 0.0817\n",
      "Epoch  17 / iter   1, loss = 0.1029\n",
      "Epoch  17 / iter   2, loss = 0.0913\n",
      "Epoch  17 / iter   3, loss = 0.0652\n",
      "Epoch  17 / iter   4, loss = 0.0159\n",
      "Epoch  18 / iter   0, loss = 0.0566\n",
      "Epoch  18 / iter   1, loss = 0.0846\n",
      "Epoch  18 / iter   2, loss = 0.1043\n",
      "Epoch  18 / iter   3, loss = 0.0843\n",
      "Epoch  18 / iter   4, loss = 0.0786\n",
      "Epoch  19 / iter   0, loss = 0.0861\n",
      "Epoch  19 / iter   1, loss = 0.0717\n",
      "Epoch  19 / iter   2, loss = 0.0923\n",
      "Epoch  19 / iter   3, loss = 0.0764\n",
      "Epoch  19 / iter   4, loss = 0.1374\n",
      "Epoch  20 / iter   0, loss = 0.0745\n",
      "Epoch  20 / iter   1, loss = 0.0858\n",
      "Epoch  20 / iter   2, loss = 0.0695\n",
      "Epoch  20 / iter   3, loss = 0.0954\n",
      "Epoch  20 / iter   4, loss = 0.0219\n",
      "Epoch  21 / iter   0, loss = 0.0859\n",
      "Epoch  21 / iter   1, loss = 0.0779\n",
      "Epoch  21 / iter   2, loss = 0.0764\n",
      "Epoch  21 / iter   3, loss = 0.0702\n",
      "Epoch  21 / iter   4, loss = 0.0767\n",
      "Epoch  22 / iter   0, loss = 0.0815\n",
      "Epoch  22 / iter   1, loss = 0.0656\n",
      "Epoch  22 / iter   2, loss = 0.0812\n",
      "Epoch  22 / iter   3, loss = 0.0726\n",
      "Epoch  22 / iter   4, loss = 0.1904\n",
      "Epoch  23 / iter   0, loss = 0.0898\n",
      "Epoch  23 / iter   1, loss = 0.0677\n",
      "Epoch  23 / iter   2, loss = 0.0678\n",
      "Epoch  23 / iter   3, loss = 0.0699\n",
      "Epoch  23 / iter   4, loss = 0.1217\n",
      "Epoch  24 / iter   0, loss = 0.0623\n",
      "Epoch  24 / iter   1, loss = 0.0847\n",
      "Epoch  24 / iter   2, loss = 0.0607\n",
      "Epoch  24 / iter   3, loss = 0.0786\n",
      "Epoch  24 / iter   4, loss = 0.0453\n",
      "Epoch  25 / iter   0, loss = 0.0815\n",
      "Epoch  25 / iter   1, loss = 0.0739\n",
      "Epoch  25 / iter   2, loss = 0.0551\n",
      "Epoch  25 / iter   3, loss = 0.0700\n",
      "Epoch  25 / iter   4, loss = 0.0479\n",
      "Epoch  26 / iter   0, loss = 0.0866\n",
      "Epoch  26 / iter   1, loss = 0.0582\n",
      "Epoch  26 / iter   2, loss = 0.0757\n",
      "Epoch  26 / iter   3, loss = 0.0566\n",
      "Epoch  26 / iter   4, loss = 0.0377\n",
      "Epoch  27 / iter   0, loss = 0.0674\n",
      "Epoch  27 / iter   1, loss = 0.0659\n",
      "Epoch  27 / iter   2, loss = 0.0642\n",
      "Epoch  27 / iter   3, loss = 0.0697\n",
      "Epoch  27 / iter   4, loss = 0.1208\n",
      "Epoch  28 / iter   0, loss = 0.0636\n",
      "Epoch  28 / iter   1, loss = 0.0675\n",
      "Epoch  28 / iter   2, loss = 0.0612\n",
      "Epoch  28 / iter   3, loss = 0.0744\n",
      "Epoch  28 / iter   4, loss = 0.0095\n",
      "Epoch  29 / iter   0, loss = 0.0697\n",
      "Epoch  29 / iter   1, loss = 0.0749\n",
      "Epoch  29 / iter   2, loss = 0.0503\n",
      "Epoch  29 / iter   3, loss = 0.0651\n",
      "Epoch  29 / iter   4, loss = 0.1367\n",
      "Epoch  30 / iter   0, loss = 0.0745\n",
      "Epoch  30 / iter   1, loss = 0.0678\n",
      "Epoch  30 / iter   2, loss = 0.0796\n",
      "Epoch  30 / iter   3, loss = 0.0457\n",
      "Epoch  30 / iter   4, loss = 0.0275\n",
      "Epoch  31 / iter   0, loss = 0.0450\n",
      "Epoch  31 / iter   1, loss = 0.0686\n",
      "Epoch  31 / iter   2, loss = 0.0623\n",
      "Epoch  31 / iter   3, loss = 0.0752\n",
      "Epoch  31 / iter   4, loss = 0.0393\n",
      "Epoch  32 / iter   0, loss = 0.0631\n",
      "Epoch  32 / iter   1, loss = 0.0410\n",
      "Epoch  32 / iter   2, loss = 0.0713\n",
      "Epoch  32 / iter   3, loss = 0.0669\n",
      "Epoch  32 / iter   4, loss = 0.1435\n",
      "Epoch  33 / iter   0, loss = 0.0668\n",
      "Epoch  33 / iter   1, loss = 0.0586\n",
      "Epoch  33 / iter   2, loss = 0.0646\n",
      "Epoch  33 / iter   3, loss = 0.0608\n",
      "Epoch  33 / iter   4, loss = 0.0225\n",
      "Epoch  34 / iter   0, loss = 0.0584\n",
      "Epoch  34 / iter   1, loss = 0.0656\n",
      "Epoch  34 / iter   2, loss = 0.0615\n",
      "Epoch  34 / iter   3, loss = 0.0531\n",
      "Epoch  34 / iter   4, loss = 0.0071\n",
      "Epoch  35 / iter   0, loss = 0.0664\n",
      "Epoch  35 / iter   1, loss = 0.0576\n",
      "Epoch  35 / iter   2, loss = 0.0335\n",
      "Epoch  35 / iter   3, loss = 0.0752\n",
      "Epoch  35 / iter   4, loss = 0.0965\n",
      "Epoch  36 / iter   0, loss = 0.0644\n",
      "Epoch  36 / iter   1, loss = 0.0673\n",
      "Epoch  36 / iter   2, loss = 0.0431\n",
      "Epoch  36 / iter   3, loss = 0.0600\n",
      "Epoch  36 / iter   4, loss = 0.0430\n",
      "Epoch  37 / iter   0, loss = 0.0713\n",
      "Epoch  37 / iter   1, loss = 0.0487\n",
      "Epoch  37 / iter   2, loss = 0.0544\n",
      "Epoch  37 / iter   3, loss = 0.0572\n",
      "Epoch  37 / iter   4, loss = 0.0741\n",
      "Epoch  38 / iter   0, loss = 0.0576\n",
      "Epoch  38 / iter   1, loss = 0.0491\n",
      "Epoch  38 / iter   2, loss = 0.0641\n",
      "Epoch  38 / iter   3, loss = 0.0536\n",
      "Epoch  38 / iter   4, loss = 0.0746\n",
      "Epoch  39 / iter   0, loss = 0.0566\n",
      "Epoch  39 / iter   1, loss = 0.0454\n",
      "Epoch  39 / iter   2, loss = 0.0611\n",
      "Epoch  39 / iter   3, loss = 0.0618\n",
      "Epoch  39 / iter   4, loss = 0.0351\n",
      "Epoch  40 / iter   0, loss = 0.0658\n",
      "Epoch  40 / iter   1, loss = 0.0340\n",
      "Epoch  40 / iter   2, loss = 0.0603\n",
      "Epoch  40 / iter   3, loss = 0.0592\n",
      "Epoch  40 / iter   4, loss = 0.0379\n",
      "Epoch  41 / iter   0, loss = 0.0538\n",
      "Epoch  41 / iter   1, loss = 0.0520\n",
      "Epoch  41 / iter   2, loss = 0.0558\n",
      "Epoch  41 / iter   3, loss = 0.0513\n",
      "Epoch  41 / iter   4, loss = 0.1088\n",
      "Epoch  42 / iter   0, loss = 0.0534\n",
      "Epoch  42 / iter   1, loss = 0.0699\n",
      "Epoch  42 / iter   2, loss = 0.0504\n",
      "Epoch  42 / iter   3, loss = 0.0441\n",
      "Epoch  42 / iter   4, loss = 0.0345\n",
      "Epoch  43 / iter   0, loss = 0.0534\n",
      "Epoch  43 / iter   1, loss = 0.0500\n",
      "Epoch  43 / iter   2, loss = 0.0481\n",
      "Epoch  43 / iter   3, loss = 0.0569\n",
      "Epoch  43 / iter   4, loss = 0.0246\n",
      "Epoch  44 / iter   0, loss = 0.0519\n",
      "Epoch  44 / iter   1, loss = 0.0475\n",
      "Epoch  44 / iter   2, loss = 0.0604\n",
      "Epoch  44 / iter   3, loss = 0.0482\n",
      "Epoch  44 / iter   4, loss = 0.0263\n",
      "Epoch  45 / iter   0, loss = 0.0550\n",
      "Epoch  45 / iter   1, loss = 0.0403\n",
      "Epoch  45 / iter   2, loss = 0.0513\n",
      "Epoch  45 / iter   3, loss = 0.0525\n",
      "Epoch  45 / iter   4, loss = 0.0756\n",
      "Epoch  46 / iter   0, loss = 0.0536\n",
      "Epoch  46 / iter   1, loss = 0.0478\n",
      "Epoch  46 / iter   2, loss = 0.0573\n",
      "Epoch  46 / iter   3, loss = 0.0395\n",
      "Epoch  46 / iter   4, loss = 0.0138\n",
      "Epoch  47 / iter   0, loss = 0.0567\n",
      "Epoch  47 / iter   1, loss = 0.0402\n",
      "Epoch  47 / iter   2, loss = 0.0435\n",
      "Epoch  47 / iter   3, loss = 0.0555\n",
      "Epoch  47 / iter   4, loss = 0.0427\n",
      "Epoch  48 / iter   0, loss = 0.0495\n",
      "Epoch  48 / iter   1, loss = 0.0446\n",
      "Epoch  48 / iter   2, loss = 0.0511\n",
      "Epoch  48 / iter   3, loss = 0.0480\n",
      "Epoch  48 / iter   4, loss = 0.0069\n",
      "Epoch  49 / iter   0, loss = 0.0485\n",
      "Epoch  49 / iter   1, loss = 0.0423\n",
      "Epoch  49 / iter   2, loss = 0.0578\n",
      "Epoch  49 / iter   3, loss = 0.0416\n",
      "Epoch  49 / iter   4, loss = 0.0379\n"
     ]
    }
   ],
   "source": [
    "# copyright (c) 2021 PaddlePaddle Authors. All Rights Reserve.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "# coding=utf-8\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def load_data():\n",
    "    # 从文件导入数据\n",
    "    datafile = './housing.data'\n",
    "    data = np.fromfile(datafile, sep=' ')\n",
    "\n",
    "    # 每条数据包括14项，其中前面13项是影响因素，第14项是相应的房屋价格中位数\n",
    "    feature_names = [ 'CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', \\\n",
    "                          'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV' ]\n",
    "    feature_num = len(feature_names)\n",
    "\n",
    "    # 将原始数据进行Reshape，变成[N, 14]这样的形状\n",
    "    data = data.reshape([data.shape[0] // feature_num, feature_num])\n",
    "\n",
    "    # 将原数据集拆分成训练集和测试集\n",
    "    # 这里使用80%的数据做训练，20%的数据做测试\n",
    "    # 测试集和训练集必须是没有交集的\n",
    "    ratio = 0.8\n",
    "    offset = int(data.shape[0] * ratio)\n",
    "    training_data = data[:offset]\n",
    "\n",
    "    # 计算训练集的最大值，最小值，平均值\n",
    "    maximums, minimums, avgs = training_data.max(axis=0), training_data.min(axis=0), training_data.sum(axis=0) / training_data.shape[0]\n",
    "\n",
    "    # 对数据进行归一化处理\n",
    "    for i in range(feature_num):\n",
    "        #print(maximums[i], minimums[i], avgs[i])\n",
    "        data[:, i] = (data[:, i] - minimums[i]) / (maximums[i] - minimums[i])\n",
    "\n",
    "    # 训练集和测试集的划分比例\n",
    "    training_data = data[:offset]\n",
    "    test_data = data[offset:]\n",
    "    return training_data, test_data\n",
    "\n",
    "class Network(object):\n",
    "    def __init__(self, num_of_weights):\n",
    "        # 随机产生w的初始值\n",
    "        # 为了保持程序每次运行结果的一致性，此处设置固定的随机数种子\n",
    "        #np.random.seed(0)\n",
    "        self.w = np.random.randn(num_of_weights, 1)\n",
    "        self.b = 0.\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = np.dot(x, self.w) + self.b\n",
    "        return z\n",
    "    \n",
    "    def loss(self, z, y):\n",
    "        error = z - y\n",
    "        num_samples = error.shape[0]\n",
    "        cost = error * error\n",
    "        cost = np.sum(cost) / num_samples\n",
    "        return cost\n",
    "    \n",
    "    def gradient(self, x, y):\n",
    "        z = self.forward(x)\n",
    "        N = x.shape[0]\n",
    "        gradient_w = 1. / N * np.sum((z-y) * x, axis=0)\n",
    "        gradient_w = gradient_w[:, np.newaxis]\n",
    "        gradient_b = 1. / N * np.sum(z-y)\n",
    "        return gradient_w, gradient_b\n",
    "    \n",
    "    def update(self, gradient_w, gradient_b, eta = 0.01):\n",
    "        self.w = self.w - eta * gradient_w\n",
    "        self.b = self.b - eta * gradient_b\n",
    "            \n",
    "                \n",
    "    def train(self, training_data, num_epochs, batch_size=10, eta=0.01):\n",
    "        n = len(training_data)\n",
    "        losses = []\n",
    "        for epoch_id in range(num_epochs):\n",
    "            # 在每轮迭代开始之前，将训练数据的顺序随机打乱\n",
    "            # 然后再按每次取batch_size条数据的方式取出\n",
    "            np.random.shuffle(training_data)\n",
    "            # 将训练数据进行拆分，每个mini_batch包含batch_size条的数据\n",
    "            mini_batches = [training_data[k:k+batch_size] for k in range(0, n, batch_size)]\n",
    "            for iter_id, mini_batch in enumerate(mini_batches):\n",
    "                #print(self.w.shape)\n",
    "                #print(self.b)\n",
    "                x = mini_batch[:, :-1]\n",
    "                y = mini_batch[:, -1:]\n",
    "                a = self.forward(x)\n",
    "                loss = self.loss(a, y)\n",
    "                gradient_w, gradient_b = self.gradient(x, y)\n",
    "                self.update(gradient_w, gradient_b, eta)\n",
    "                losses.append(loss)\n",
    "                print('Epoch {:3d} / iter {:3d}, loss = {:.4f}'.\n",
    "                                 format(epoch_id, iter_id, loss))\n",
    "        \n",
    "        return losses\n",
    "def train():\n",
    "    # 获取数据\n",
    "    train_data, test_data = load_data()\n",
    "\n",
    "    # 创建网络\n",
    "    net = Network(13)\n",
    "    # 启动训练\n",
    "    losses = net.train(train_data, num_epochs=50, batch_size=100, eta=0.1)\n",
    "\n",
    "    # 画出损失函数的变化趋势\n",
    "    # plot_x = np.arange(len(losses))\n",
    "    # plot_y = np.array(losses)\n",
    "    # plt.plot(plot_x, plot_y)\n",
    "    # plt.show()\n",
    "\n",
    "def plot_3D_neural_work_weight():\n",
    "    # 获取数据\n",
    "    training_data, test_data = load_data()\n",
    "    x = training_data[:, :-1]\n",
    "    y = training_data[:, -1:]\n",
    "\n",
    "    net = Network(13)\n",
    "    # losses = []\n",
    "    # #只画出参数w5和w9在区间[-160, 160]的曲线部分，以及包含损失函数的极值\n",
    "    # w5 = np.arange(-160.0, 160.0, 1.0)\n",
    "    # w9 = np.arange(-160.0, 160.0, 1.0)\n",
    "    # losses = np.zeros([len(w5), len(w9)])\n",
    "\n",
    "    # #计算设定区域内每个参数取值所对应的Loss\n",
    "    # for i in range(len(w5)):\n",
    "    #     for j in range(len(w9)):\n",
    "    #         net.w[5] = w5[i]\n",
    "    #         net.w[9] = w9[j]\n",
    "    #         z = net.forward(x)\n",
    "    #         loss = net.loss(z, y)\n",
    "    #         losses[i, j] = loss\n",
    "\n",
    "    # #使用matplotlib将两个变量和对应的Loss作3D图\n",
    "    # fig = plt.figure()\n",
    "    # ax = Axes3D(fig)\n",
    "\n",
    "    # w5, w9 = np.meshgrid(w5, w9)\n",
    "\n",
    "    # ax.plot_surface(w5, w9, losses, rstride=1, cstride=1, cmap='rainbow')\n",
    "    # plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # plot_3D_neural_work_weight()\n",
    "    train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
